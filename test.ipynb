{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.utils as tvu\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from models.ddpm.diffusion import DDPM\n",
    "# from models.improved_ddpm.script_util import i_DDPM\n",
    "# from utils.text_dic import SRC_TRG_TXT_DIC\n",
    "# from utils.diffusion_utils import get_beta_schedule, denoising_step\n",
    "# from losses import id_loss\n",
    "# from losses.clip_loss import CLIPLoss\n",
    "from datasets.CelebA_HQ_dataset import get_celeba_dataset\n",
    "from datasets.data_utils import get_dataset, get_dataloader\n",
    "from configs.paths_config import DATASET_PATHS, MODEL_PATHS, HYBRID_MODEL_PATHS, HYBRID_CONFIG\n",
    "# from datasets.imagenet_dic import IMAGENET_DIC\n",
    "# from utils.align_utils import run_alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.8118, -0.8745, -0.5529,  ..., -0.9608, -0.9686, -0.9765],\n",
      "          [-0.8510, -0.7490, -0.4118,  ..., -0.9608, -0.9686, -0.9686],\n",
      "          [-0.8431, -0.6392, -0.3490,  ..., -0.9608, -0.9686, -0.9686],\n",
      "          ...,\n",
      "          [-0.6078, -0.5216, -0.4745,  ..., -0.8039, -0.8039, -0.8118],\n",
      "          [-0.6863, -0.5922, -0.5451,  ..., -0.8196, -0.8275, -0.8353],\n",
      "          [-0.7176, -0.6392, -0.6157,  ..., -0.8353, -0.8353, -0.8353]],\n",
      "\n",
      "         [[-0.8510, -0.9137, -0.5922,  ..., -0.9608, -0.9686, -0.9765],\n",
      "          [-0.8824, -0.7804, -0.4431,  ..., -0.9608, -0.9686, -0.9686],\n",
      "          [-0.8980, -0.6941, -0.4039,  ..., -0.9608, -0.9686, -0.9686],\n",
      "          ...,\n",
      "          [-0.6784, -0.5922, -0.5451,  ..., -0.7882, -0.7882, -0.7961],\n",
      "          [-0.7569, -0.6627, -0.6157,  ..., -0.8039, -0.8118, -0.8196],\n",
      "          [-0.7882, -0.7098, -0.6863,  ..., -0.8196, -0.8196, -0.8196]],\n",
      "\n",
      "         [[-0.8980, -0.9608, -0.6392,  ..., -0.9608, -0.9686, -0.9765],\n",
      "          [-0.9529, -0.8510, -0.5137,  ..., -0.9608, -0.9686, -0.9686],\n",
      "          [-0.9608, -0.7569, -0.4667,  ..., -0.9608, -0.9686, -0.9686],\n",
      "          ...,\n",
      "          [-0.7176, -0.6314, -0.5843,  ..., -0.8275, -0.8275, -0.8353],\n",
      "          [-0.7961, -0.7020, -0.6549,  ..., -0.8431, -0.8510, -0.8588],\n",
      "          [-0.8275, -0.7490, -0.7255,  ..., -0.8588, -0.8588, -0.8588]]]]), [tensor([1]), tensor([-1]), tensor([-1])]]\n"
     ]
    }
   ],
   "source": [
    "a = {}\n",
    "a, b, c = get_celeba_dataset(DATASET_PATHS[\"CelebA_HQ\"], a)\n",
    "dl = torch.utils.data.DataLoader(a, batch_size=2)\n",
    "for e in dl:\n",
    "    print(e)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71b8598232e9da840c9f4d0c9af37b9b2d2abaa12e34b6ca4de8dbe97a84b5eb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ddpm-playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
